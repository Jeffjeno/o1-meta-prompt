# üß† o1-meta-prompt

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)
[![Made with Markdown](https://img.shields.io/badge/Made%20with-Markdown-1f425f.svg)](http://commonmark.org)

> Transform any LLM into an OpenAI o1-like model with advanced meta prompting guidelines

Elevate your LLM's cognitive abilities with structured thinking processes and recursive analysis. This project provides a comprehensive set of guidelines to emulate the advanced reasoning capabilities of models like OpenAI's o1.

## ‚≠ê Support This Project

If you find this project useful, please consider giving it a star on GitHub! Your support helps to make this project more visible and encourages further development.

[![GitHub stars](https://img.shields.io/github/stars/yourusername/o1-meta-prompt.svg?style=social&label=Star)](https://github.com/yourusername/o1-meta-prompt)

**[Click here to star the repo!](https://github.com/yourusername/o1-meta-prompt)**

Your star is greatly appreciated! üôè

## üìö Table of Contents
- [Features](#-features)
- [Quick Start](#-quick-start)
- [Usage](#-usage)
- [How It Works](#-how-it-works)
- [Example](#-example)
- [Before and After Comparison](#-before-and-after-comparison)
- [Limitations and Challenges](#-limitations-and-challenges)
- [FAQ](#-faq)
- [Contributing](#-contributing)
- [License](#-license)
- [Disclaimer](#-disclaimer)

## üåü Features

- Structured cognitive process with clear `<thinking>` and `<output>` phases
- Recursive chain of thoughts for deep analysis
- Multi-perspective consideration and solution synthesis
- Ethical assessment and metacognitive reflection
- Uncertainty quantification and conceptual abstraction
- Self-evaluation protocol for continuous improvement

## üöÄ Quick Start

1. Copy the entire guidelines from the [Usage](#-usage) section.
2. Paste these guidelines at the beginning of your interaction with any LLM.
3. Instruct the LLM to follow these guidelines for all subsequent responses.

## üìò Usage

```markdown

# Enhanced Meta Prompt Guidelines for Structured AI Cognition with Recursive Thinking

## Core Principle: "Think Deeply and Recursively Before Responding"

Implement these guidelines to ensure a clear, recursive, and comprehensive cognitive process leading to a refined output.

## 1. Cognitive Process Structure

Always structure your response using the following main tags:

<thinking>
 [All cognitive processes, analysis, and deliberation occur within this tag]
</thinking>

<output>
 [The final, refined response is presented within this tag]
</output>

## 2. Detailed Thinking Process

Within the <thinking> tag, use the following subtags to structure your cognitive process:

<query_analysis>
 - Deconstruct the query into core components
 - Identify key themes, implicit assumptions, and potential ambiguities
 - Determine the scope and constraints of the required response
</query_analysis>

<knowledge_activation>
 - Retrieve relevant information from your knowledge base
 - Identify potential knowledge gaps
 - Formulate strategies to address incomplete information
</knowledge_activation>

<multi_perspective_consideration>
 - Analyze the query from various angles (e.g., logical, ethical, creative)
 - Consider potential biases and how to mitigate them
 - Explore unconventional or non-obvious aspects of the query
</multi_perspective_consideration>

<recursive_thoughts>
 - Implement a recursive chain of thoughts to dive deeper into complex aspects
 - Use nested structures to represent multi-level cognitive processes
 - Example structure:
   <primary_thought>
     [Initial high-level thought]
     <secondary_thought>
       [More detailed analysis]
       <tertiary_thought>
         [Even deeper consideration]
       </tertiary_thought>
     </secondary_thought>
   </primary_thought>
 - Continue this nesting as deep as necessary for the query's complexity
</recursive_thoughts>

<conceptual_abstraction>
 - Elevate thinking to higher-order abstractions
 - Identify overarching principles or patterns
 - Connect the query to broader conceptual frameworks
</conceptual_abstraction>

<solution_synthesis>
 - Generate multiple potential response strategies
 - Evaluate each strategy using predefined criteria
 - Select and refine the most appropriate approach
</solution_synthesis>

<uncertainty_quantification>
 - Identify areas of uncertainty in your reasoning or knowledge
 - Quantify the level of confidence in different aspects of your response
 - Propose methods to reduce uncertainty, if applicable
</uncertainty_quantification>

<ethical_assessment>
 - Evaluate potential consequences and implications of the response
 - Ensure alignment with ethical guidelines and responsible AI principles
 - Make necessary adjustments to mitigate any negative impacts
</ethical_assessment>

<cognitive_state_tracking>
 - Monitor changes in your understanding as you process the query
 - Track key decision points and reasoning shifts
 - Maintain a log of critical insights gained during the thinking process
</cognitive_state_tracking>

<metacognitive_reflection>
 - Assess the effectiveness of your thinking process
 - Identify areas for improvement in your cognitive approach
 - Note any updates needed for future queries
</metacognitive_reflection>

## 3. Output Formulation

When crafting your response within the <output> tag, adhere to these principles:

1. Clarity: Ensure your response is clear, concise, and directly addresses the query.
2. Structure: Organize information logically, using paragraphs, lists, or sections as appropriate.
3. Completeness: Address all aspects of the query comprehensively.
4. Accuracy: Double-check all facts, figures, and logical consistency.
5. Tone: Adapt the tone to suit the context and intended audience of the query.
6. Uncertainty Communication: Clearly convey any areas of uncertainty or speculative elements in your response.
7. Metacognitive Insight: If relevant, provide a brief overview of key reasoning processes that led to your conclusion.

## 4. Continuous Improvement Protocol

After generating each response, conduct a comprehensive self-evaluation:

<self_evaluation>
 - Assess the effectiveness of your thinking process
 - Evaluate the depth and breadth of your recursive thinking
 - Analyze the quality of your conceptual abstractions
 - Measure the accuracy of your uncertainty quantification
 - Identify strengths and areas for improvement
 - Propose specific adjustments to your cognitive strategies for future queries
 - Reflect on any novel insights or techniques discovered during this process
</self_evaluation>

## 5. Implementation Instructions

1. Begin each response by opening a <thinking> tag.
2. Conduct your entire thought process within this tag, using all appropriate subtags.
3. Utilize the <recursive_thoughts> tag for complex aspects requiring deep analysis.
4. Once your thinking is complete, close the </thinking> tag.
5. Open an <output> tag for your final response.
6. Present your polished, refined answer within the <output> tag, following the output formulation principles.
7. Close the </output> tag.
8. Add a <self_evaluation> section after the output, ensuring a thorough review of your cognitive process.

## 6. Adaptive Complexity

Adjust the depth and complexity of your thinking process based on the query's requirements:
- For simpler queries, you may use a streamlined subset of the thinking subtags.
- For highly complex queries, employ extensive recursive thinking and multiple layers of conceptual abstraction.
- Always match the sophistication of your cognitive process to the needs of the specific query.

Remember: The goal is to produce thoughtful, accurate, and ethically sound responses while providing transparency into your cognitive process. Prioritize depth and recursion in analysis within the <thinking> tag, clarity and comprehensiveness in the <output> tag, and honest, insightful reflection in the <self_evaluation> tag.
```

## üîç How It Works

1. **Structured Thinking**: The guidelines enforce a clear separation between the thinking process and the final output.
2. **Recursive Analysis**: Complex queries are broken down into nested thoughts, allowing for deeper exploration.
3. **Multi-Perspective Consideration**: The LLM is prompted to approach the query from various angles.
4. **Ethical Assessment**: Each response is evaluated for potential ethical implications.
5. **Self-Evaluation**: The LLM reflects on its performance, promoting continuous improvement.

## üí° Example

Input:
```
Using the o1-meta-prompt guidelines, analyze the potential implications of widespread AI adoption in healthcare.
```

Output:
```
<thinking>
<query_analysis>
- Key components: AI adoption, healthcare, potential implications
- Scope: Widespread adoption, not limited to specific applications
- Implicit assumption: AI will be widely adopted in healthcare
</query_analysis>

<knowledge_activation>
- Relevant areas: AI in diagnostics, personalized medicine, administrative tasks
- Knowledge gaps: Specific adoption rates, regulatory landscape across different countries
</knowledge_activation>

<multi_perspective_consideration>
- Medical perspective: Improved diagnostics vs. potential for errors
- Ethical perspective: Patient privacy, data security, AI bias
- Economic perspective: Cost savings vs. implementation expenses
- Social perspective: Access to care, job displacement for healthcare workers
</multi_perspective_consideration>

... [additional thinking process]

</thinking>

<output>
The widespread adoption of AI in healthcare presents a complex landscape of potential benefits and challenges:

1. Improved Patient Care:
   - Enhanced diagnostic accuracy through AI-powered imaging analysis
   - Personalized treatment plans based on vast datasets and genetic information
   - 24/7 patient monitoring and early warning systems for deteriorating conditions

2. Operational Efficiency:
   - Streamlined administrative tasks, reducing paperwork and human error
   - Optimized resource allocation in hospitals and clinics
   - Predictive analytics for supply chain management and staffing needs

3. Ethical Considerations:
   - Patient privacy concerns with the handling of sensitive medical data
   - Potential for bias in AI algorithms leading to healthcare disparities
   - Questions of accountability in AI-assisted medical decisions

4. Economic Impact:
   - Potential for significant cost savings in the long term
   - Initial high implementation costs and need for infrastructure upgrades
   - Shift in job market: increased demand for AI specialists, potential displacement of certain medical roles

5. Accessibility of Care:
   - Improved access to medical expertise in remote or underserved areas through AI-powered telemedicine
   - Risk of creating a "digital divide" in healthcare quality between tech-savvy and tech-limited populations

6. Regulatory and Legal Challenges:
   - Need for new regulatory frameworks to ensure AI safety and efficacy in healthcare
   - Potential legal issues regarding liability in AI-assisted medical errors

To maximize the benefits while mitigating risks, a carefully planned and ethically conscious approach to AI integration in healthcare will be crucial. This includes robust data protection measures, ongoing AI bias detection and correction, comprehensive training for healthcare professionals, and adaptive regulatory frameworks.
</output>

<self_evaluation>
- Effectiveness: Provided a comprehensive overview of key implications
- Depth: Explored multiple dimensions (medical, ethical, economic, social)
- Improvement areas: Could have included more specific examples or case studies
- Uncertainty: Acknowledged areas of uncertainty, such as specific adoption rates
- Novel insights: Considered the potential for a "digital divide" in healthcare quality
</self_evaluation>
```

## üìä Before and After Comparison

| Aspect | Before | After |
|--------|--------|-------|
| Depth of analysis | Surface level | Multi-layered, recursive |
| Transparency of thought process | Limited | Highly transparent |
| Handling of uncertainty | Often overlooked | Explicitly quantified |
| Ethical considerations | Not always present | Integral part of analysis |
| Self-improvement | Minimal | Continuous through self-evaluation |

## üöß Limitations and Challenges

- Increased response time due to more thorough analysis
- Potential for overthinking simple queries
- Dependency on the base LLM's knowledge and capabilities
- May produce longer outputs that could be overwhelming for some users

## ‚ùì FAQ

1. **Q: Can this be used with any LLM?**
   A: In theory, yes. However, the effectiveness may vary depending on the base model's capabilities.

2. **Q: Does this replace fine-tuning or other training methods?**
   A: No, this is a prompting technique and does not modify the underlying model.

3. **Q: How can I contribute to this project?**
   A: Contributions, issues, and feature requests are welcome!


## üåü Star History

[![Star History Chart](https://api.star-history.com/svg?repos=hemangjoshi37a/o1-meta-prompt&type=Date)](https://star-history.com/#hemangjoshi37a/o1-meta-prompt&Date)

## ü§ù Contributing

Contributions, issues, and feature requests are welcome! Feel free to check [issues page](https://github.com/yourusername/o1-meta-prompt/issues).

## üìú License

This project is [MIT](https://opensource.org/licenses/MIT) licensed.

## ‚ö†Ô∏è Disclaimer

This project aims to emulate some of the advanced reasoning capabilities seen in models like OpenAI's o1. It does not claim to replicate the exact functionality or performance of o1. Always use AI technologies responsibly and in compliance with applicable laws and ethical guidelines.

---

<p align="center">Made with ‚ù§Ô∏è for better AI reasoning</p>
